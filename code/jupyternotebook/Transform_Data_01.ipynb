{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###import modules###\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../myenv/lib/python3.7/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Time: # change class name to Time\n",
    "    \n",
    "    \"\"\"Time stamp for code execution\"\"\"\n",
    "        \n",
    "    def get_current_time(self):\n",
    "        now = datetime.datetime.now()\n",
    "        return(now)\n",
    "    \n",
    "    def get_start_time(self):\n",
    "        # Start time\n",
    "        start_time = self.get_current_time()\n",
    "        return(start_time)\n",
    "       \n",
    "    def get_end_time(self):\n",
    "        # End time\n",
    "        end_time = self.get_current_time()\n",
    "        elapsed_time = end_time - self.get_start_time()\n",
    "        return(end_time, elapsed_time)\n",
    "        \n",
    "    def print_start(self):\n",
    "        print('--------Start Script--------')\n",
    "        print('--------Start Time: ' + self.get_start_time().strftime('%Y-%m-%d %H:%M:%S') + '-------\\n')\n",
    "\n",
    "    def print_end(self):\n",
    "        print('Total ' + str(self.get_end_time()[1].seconds) + ' [sec]')\n",
    "        print('-----End Time : ' + self.get_end_time()[0].strftime('%Y-%m-%d %H:%M:%S') + ' ---------')\n",
    "        print('-----END SCRIPT------') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "    \n",
    "    \"\"\"Clean and transform data\"\"\"\n",
    "    \n",
    "    def find_first_col(self, df):\n",
    "        for i in range(2):\n",
    "            test = [col for col in df[df.columns[i]].values]\n",
    "            try:\n",
    "                any('北海' in s for s in test) or any('沖縄' in s for s in test)\n",
    "                return(i)\n",
    "            except:\n",
    "               print('Warning: Not the starting column number.')\n",
    "    \n",
    "    def format_data(self, cleantext):\n",
    "        # Converting string to list \n",
    "        res = cleantext.strip('][').split(', ') \n",
    "        return(res)\n",
    "\n",
    "    def list_slice(self, S, step):\n",
    "        return [S[i::step] for i in range(step)]\n",
    "    \n",
    "    def check_header(self, list_df):\n",
    "        print(\"First value in list: \" + list_df[0])\n",
    "        if '国' in list_df[0]:\n",
    "            list_df\n",
    "        elif '感染' in list_df[0]:\n",
    "            list_df.insert(0, '国・地域')\n",
    "        else:\n",
    "            print(\"Error: Starting value of data is neither 国, 感染\")\n",
    "        return(list_df)\n",
    "\n",
    "    def check_row_num(self, list_df):\n",
    "        #check if length of rows match\n",
    "        num_rows = []\n",
    "        check = [len(list_df[row]) for row in range(len(list_df))]\n",
    "        if len(set(check)) == 1:\n",
    "            print(\"Number of rows in lists are equal, ready to construct dataframe.\")\n",
    "        else:\n",
    "            print(\"Error: Number of rows in list are unequal.\")\n",
    "            \n",
    "    def create_df(self, list_df):\n",
    "        df = pd.DataFrame()\n",
    "        df['Country'] = list_df[0][1:]\n",
    "        df['Infected'] = list_df[1][1:]\n",
    "        df['Deaths'] = list_df[2][1:]\n",
    "        print(df.head())\n",
    "        return(df)\n",
    "            \n",
    "    def change_type(self, df, col_name, data_type):\n",
    "        df[col_name] = df[col_name].astype(data_type)\n",
    "        return(df)\n",
    "        \n",
    "    def drop_col(self, df, list_col_num):\n",
    "        # Drop column\n",
    "        for col_num in list_col_num:\n",
    "            df = df.drop(df.columns[col_num], axis=1)\n",
    "        return(df)\n",
    "    \n",
    "    def replace(self, df, col_name, target_list, replacement):\n",
    "        for target in target_list:\n",
    "            df[col_name] = df[col_name].str.replace(target, replacement)\n",
    "        return(df)\n",
    "    \n",
    "    def fix_prefecture_name(self, df):\n",
    "        test_df = df.to_dict('index')\n",
    "        for pref in test_df.keys():\n",
    "            if ('県' in pref or '東京都' in pref or '府' in pref):\n",
    "                n_pref = pref\n",
    "                print(\"Prefecture name already formatted\")\n",
    "            elif ('県' not in pref and '東京' not in pref and '大阪' not in pref and '京都' not in pref and '北海道' not in pref):\n",
    "                n_pref = pref + '県'\n",
    "            elif ('東京' in pref):\n",
    "                n_pref = pref + '都'\n",
    "            elif('大阪' in pref or '京都' in pref):\n",
    "                n_pref = pref + '府'\n",
    "            elif('北海道' in pref):\n",
    "                n_pref = pref\n",
    "            else:\n",
    "                print(\"Warning: Prefecture name may not be formatted correctly.\")\n",
    "            test_df[pref]['pref'] = n_pref\n",
    "        return(test_df)\n",
    "        \n",
    "    def check_data(self, ff_df, df):\n",
    "        sample = ff_df.sample() #sample data from final df\n",
    "        test_pref = sample['pref']\n",
    "        check_df1 = df.loc[test_pref] #get data from original data\n",
    "        for i in check_df1:\n",
    "            if check_df1[i].values == sample[i].values:\n",
    "                print('Values match:{}:{} = {}'.format(i, check_df1[i].values, sample[i].values))\n",
    "            else:\n",
    "                print('Error: Values do not match:{}:{} = {}'.format(i, check_df1[i].values, sample[i].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class File():\n",
    "    \n",
    "    \"\"\"Access Files\"\"\"\n",
    "    \n",
    "    def append_value(self, dict_obj, key, value):\n",
    "        # Check if key exist in dict or not\n",
    "        if key in dict_obj.keys():\n",
    "            dict_obj[key].append(value)\n",
    "        else:\n",
    "            dict_obj[key] = [value]\n",
    "\n",
    "    def get_paths(self, mypath, ending, starting=\"2020_\"):\n",
    "        file_paths = {}\n",
    "        for file in os.listdir(mypath):\n",
    "            if file.startswith(starting) and file.endswith(tuple(ending)):\n",
    "                group_key = file.rsplit('_')\n",
    "                key = '_'.join(group_key[:3])\n",
    "                self.append_value(file_paths, key, file)\n",
    "            else:\n",
    "                pass\n",
    "        return(file_paths)\n",
    "    \n",
    "    def get_recent_file(self, get_paths_dict):\n",
    "        d = [datetime.datetime.strptime(day, '%Y_%m_%d') for day in get_paths_dict.keys()]\n",
    "        target = sorted(d)[-1]\n",
    "        find_key = \"{}_{}_{}\".format(target.year, target.month, target.day)\n",
    "        recent_file = csv_paths[find_key][0]\n",
    "        return(recent_file)\n",
    "            \n",
    "    def export_table(self, table, file_name, file_type):\n",
    "        # export individually\n",
    "        path = '../../data/transformed/'\n",
    "        \n",
    "        if file_type == \"csv\":\n",
    "            file_type = \".csv\"\n",
    "            table.to_csv(path + file_name + file_type)\n",
    "        elif file_type == \"txt\":\n",
    "            file_type = \".txt\"\n",
    "            with open(path + file_name + file_type, \"w\") as text_file:\n",
    "                text_file.write(table)\n",
    "        else:\n",
    "            print('Error: Indicate data, filename, filetype - txt or csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcr_japan(mypath, csv_paths):\n",
    "    data = Data()\n",
    "    file = File()\n",
    "    \n",
    "    \"\"\"国内における都道府県別のPCR検査陽性者数\"\"\"\n",
    "    \n",
    "    for key, value in csv_paths.items():\n",
    "        frames = []\n",
    "        for i, file_n in enumerate(value):\n",
    "            print('data{}'.format(i) +  \": \" + file_n)\n",
    "            df = pd.read_csv(mypath + file_n, header=1)\n",
    "            print(\"length of df: \" + str(len(df)))\n",
    "\n",
    "            ###Step2: Manipulate data###\n",
    "            start = data.find_first_col(df)\n",
    "            print(start)\n",
    "            # Drop first column\n",
    "            df = df.iloc[:, start:start+3]\n",
    "\n",
    "            # Rename columns\n",
    "            df.columns = [\"Prefecture\", \"Positive\", \"Tested\"]\n",
    "            \n",
    "            df = data.change_type(df, 'Prefecture', str)\n",
    "            df = data.change_type(df, 'Positive', str)\n",
    "            df = data.change_type(df, 'Tested', str)\n",
    "\n",
    "            # Replace \n",
    "            df = data.replace(df, 'Prefecture', ['※','\\n','\\d+', ',,', '、', ' ', ',', '\\(/～\\）', '\\(その他\\)県', '\\(～/\\)', '⻑崎船その他県', '⻑崎船その他その他県', '合計\\　県'], '')\n",
    "            df = data.replace(df, 'Positive', [',', ' ', '\\n', '\\(208\\)', '\\(195\\)', r\"\\(.*\\)\", '※', '名'], '')\n",
    "            df = data.replace(df, 'Tested', [',', '※1', '※１', 'HP', 'nan', '※2', '-'], '')\n",
    "            df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "            df = df.reset_index() \n",
    "            \n",
    "            print(df)\n",
    "\n",
    "            # Drop last two rows\n",
    "            df = df[df.Prefecture != '合計']\n",
    "            df = df[df.Prefecture != 'その他']\n",
    "            df = df[df.Prefecture != '⾧崎船その他']\n",
    "            df = df[df.Prefecture != '長崎船その他']\n",
    "            frames.append(df)\n",
    "\n",
    "        result = pd.concat(frames)\n",
    "\n",
    "        #check row length\n",
    "        print(\"Length of df should be 47: \" + str(len(result)))\n",
    "\n",
    "        # change col type\n",
    "        result = data.change_type(result, 'Positive', int)\n",
    "        result = data.change_type(result, 'Tested', float)\n",
    "        result = data.drop_col(result, [0])\n",
    "        result = result.set_index('Prefecture')\n",
    "        fix_pref = data.fix_prefecture_name(result)\n",
    "        result = pd.DataFrame.from_dict(fix_pref, orient='index') \n",
    "        result = result.set_index('pref')\n",
    "        \n",
    "        #add percent col\n",
    "        result['Percent'] = (result['Positive']/result[\"Tested\"])*100\n",
    "        result['Percent'] = result['Percent'].round(decimals=2)\n",
    "        \n",
    "        print(result.head())\n",
    "        ###Step3: Export data###\n",
    "        # export data to 'data/transformed/'\n",
    "        file.export_table(result, '{}_corona_jp'.format(key), 'csv')\n",
    "       \n",
    "\n",
    "        \n",
    "def corona_country(mypath, txt_paths):\n",
    "    data = Data()\n",
    "    file = File()\n",
    "    \n",
    "    \"\"\"国別コロナ数\"\"\"\n",
    "\n",
    "    for key, value in txt_paths.items():\n",
    "        print('data-{}'.format(key) +  \": \" + mypath + value)\n",
    "\n",
    "        # Access file content\n",
    "        file1 = open(mypath+value,\"r\") \n",
    "        clean_data = file1.readlines(0)[0]\n",
    "        file1.close()\n",
    "\n",
    "        # ###Step2: Manipulate data###\n",
    "        list_df = data.format_data(clean_data)\n",
    "        while \"'名'\" in list_df: list_df.remove(\"'名'\")\n",
    "        while \"'※'\" in list_df: list_df.remove(\"'※'\")\n",
    "        while \"'（英王室属領）'\" in list_df: list_df.remove(\"'（英王室属領）'\")\n",
    "        while \"'ヘルツェゴビナ'\" in list_df: list_df.remove(\"'ヘルツェゴビナ'\")\n",
    "        while \"'バーブーダ'\" in list_df: list_df.remove(\"'バーブーダ'\")\n",
    "        while \"'ネービス'\" in list_df: list_df.remove(\"'ネービス'\")\n",
    "        while \"'クレナディーン諸島'\" in list_df: list_df.remove(\"'クレナディーン諸島'\")\n",
    "        while \"'及びクレナディーン諸島'\" in list_df: list_df.remove(\"'及びクレナディーン諸島'\")\n",
    "        while \"'（英領）'\" in list_df: list_df.remove(\"'（英領）'\")\n",
    "        while \"'カイコス諸島（英領）'\" in list_df: list_df.remove(\"'カイコス諸島（英領）'\")    \n",
    "\n",
    "        list_df = data.check_header(list_df)\n",
    "        list_df = data.list_slice(list_df[0:],3)\n",
    "\n",
    "        data.check_row_num(list_df)\n",
    "        df = data.create_df(list_df)\n",
    "\n",
    "        # Replace \n",
    "        df = data.replace(df, 'Country', [r\"[\\\"\\',]\"], '')\n",
    "        df = data.replace(df, 'Infected', [r\"[\\\"\\',]\", '名'], '')\n",
    "        df = data.replace(df, 'Deaths', [r\"[\\\"\\',]\", '名'], '')\n",
    "        df = data.change_type(df, 'Infected', int)\n",
    "        df = data.change_type(df, 'Deaths', int)\n",
    "        df.head()\n",
    "\n",
    "        ###Step3: Export data###\n",
    "        # export data to 'data/transformed/'\n",
    "        file.export_table(df, '{}_corona_country'.format(key), 'csv')\n",
    "        \n",
    "def population_jpn(mypath, path):\n",
    "    data = Data()\n",
    "    file = File()\n",
    "    \n",
    "    \"\"\"国内における都道府県別の人口\"\"\"\n",
    "\n",
    "    for key, value in path.items():\n",
    "        frames = []\n",
    "        for file_n in value:\n",
    "            # read in data\n",
    "            df = pd.read_csv(mypath+file_n, header=0)\n",
    "            ###Step2: Manipulate data###\n",
    "            # Drop first column\n",
    "            df = df.drop(df.columns[0], axis=1)\n",
    "            df = df.set_index('pref')\n",
    "            # Replace \n",
    "            col_name = file_n.rsplit('_')[3:][0][:-4]\n",
    "            df = data.replace(df, col_name, [','], '')\n",
    "\n",
    "            # change col type\n",
    "            if col_name == 'popDensity' or col_name == 'area':\n",
    "                df = data.change_type(df, col_name, float)\n",
    "            elif col_name == 'population':\n",
    "                df = data.change_type(df, col_name, int)\n",
    "            else:\n",
    "                Print(\"Error: No such column name exist: {}\".format(col_name))\n",
    "\n",
    "            frames.append(df)\n",
    "\n",
    "        final_df = pd.concat(frames, axis=1, join='inner')\n",
    "        ff_df = final_df.reset_index()\n",
    "        data.check_data(ff_df, df)\n",
    "        print(final_df.dtypes)\n",
    "        print(final_df.head())\n",
    "\n",
    "        ###Step3: Export data###\n",
    "        # export data to 'data/transformed/'\n",
    "        file.export_table(final_df, '{}_population_jp'.format(key), 'csv')\n",
    "        \n",
    "def time_series_df(mypath, file_paths):\n",
    "    data = Data()\n",
    "    file = File()\n",
    "    \n",
    "    \"\"\"Construct time series data\"\"\"\n",
    "    \n",
    "    frames = []\n",
    "    for key, value in file_paths.items():\n",
    "            # read in data\n",
    "            print(\"Date of data: {}\".format(key))\n",
    "            df = pd.read_csv(mypath+value[0], header=0)\n",
    "            ###Step2: Manipulate data###\n",
    "#             df = df.drop(['Tested','Percent'], axis=1)  # Drop columns 'Positive', 'Tested', 'Percent'\n",
    "            df = df.drop(['Positive', 'Percent'], axis=1)\n",
    "            df = data.replace(df, 'pref', [','], '')\n",
    "            print(\"Number of prefectures: {}\".format(len(df['pref'])))\n",
    "            df = df.set_index('pref')  # set index to prefectures\n",
    "            d = datetime.datetime.strptime(key, '%Y_%m_%d')\n",
    "            d = d.date() # convert datetime object to date object\n",
    "            df.columns = ['{}'.format(d.isoformat())]\n",
    "            frames.append(df)\n",
    "    result = pd.concat(frames, axis=1, join='outer')\n",
    "    df_transposed = result.T\n",
    "    df_reset = df_transposed.reset_index()\n",
    "    df_final=df_reset.rename(columns = {'index':'date'})\n",
    "    df_final=df_final.sort_values('date')\n",
    "    print(\"Number of prefectures: {}\".format(len(df_final.columns)))\n",
    "    print(df_final.columns)\n",
    "    tmp = []\n",
    "    for col in df_final.columns:\n",
    "        tmp.append(str(col))\n",
    "    print('check this: {}'.format(len(set(tmp))))\n",
    "    \n",
    "    # find missing dates \n",
    "    d = [datetime.datetime.strptime(day, '%Y-%m-%d') for day in df_final['date'].tolist()]\n",
    "    date_set = set(d[0] + datetime.timedelta(x) for x in range((d[-1] - d[0]).days))\n",
    "    missing = sorted(date_set - set(d))\n",
    "    print(\"Missing data: {}\".format(missing))\n",
    "\n",
    "    ###Step3: Export data###\n",
    "    # export data to 'data/transformed/'\n",
    "#     file.export_table(df_final, 'corona_bytime_jp_today', 'csv')\n",
    "    file.export_table(df_final, 'corona_bytime_jp_tested', 'csv')\n",
    "    \n",
    "def format_missing_data(mypath, filename):\n",
    "    \n",
    "    \"\"\"Format Missing Data\"\"\"\n",
    "\n",
    "    data = Data()\n",
    "    file = File()\n",
    "    \n",
    "    df = pd.read_csv(mypath+filename, header=0)\n",
    "    df = df.drop(['Unnamed: 0'], axis=1)  # Drop columns\n",
    "    for i in range(len(df)):\n",
    "        if df.iloc[i][1] == '北海道':\n",
    "            df.iloc[i][1] = '北海道県'\n",
    "        else:\n",
    "            pass\n",
    "    date_dict = {'date': []}    \n",
    "    temp_df = {\n",
    "    '滋賀県':[],'京都府':[],'大阪府':[],'兵庫県':[],'奈良県':[],\n",
    "    '和歌山県':[],'鳥取県':[],'島根県':[],'岡山県':[],'広島県':[],\n",
    "    '山口県':[],'徳島県':[],'香川県':[],'愛媛県':[],'高知県':[],\n",
    "    '福岡県':[],'佐賀県':[],'長崎県':[],'熊本県':[],'大分県':[],\n",
    "    '宮崎県':[],'鹿児島県':[],'沖縄県':[],'北海道':[],'青森県':[],\n",
    "    '岩手県':[],'宮城県':[],'秋田県':[],'山形県':[],'福島県':[],\n",
    "    '茨城県':[],'栃木県':[],'群馬県':[],'埼玉県':[],'千葉県':[],\n",
    "    '東京都':[],'神奈川県':[],'新潟県':[],'富山県':[],'石川県':[],\n",
    "    '福井県':[],'山梨県':[],'長野県':[],'岐阜県':[],'静岡県':[],\n",
    "    '愛知県':[],'三重県':[],\n",
    "    }\n",
    "    for i in range(len(df)):\n",
    "        date_dict['date'].append(df.iloc[i][0])\n",
    "        for key in temp_df:\n",
    "            if df.iloc[i][1] == key:\n",
    "                temp_df[key].append(1)\n",
    "            else:\n",
    "                temp_df[key].append(0)\n",
    "                \n",
    "    date_dict.update(temp_df)\n",
    "    final_df = pd.DataFrame.from_dict(date_dict)\n",
    "    final_df = final_df[final_df.date != '調査中']\n",
    "    final_df = data.replace(final_df, 'date', [\"/\"], \"-\")\n",
    "    final_df['date'] = pd.to_datetime(final_df['date'])\n",
    "    print('Number of prefectures: {}'.format(len(final_df.columns)))\n",
    "    \n",
    "    return(final_df)\n",
    "\n",
    "def concat_missing_data(org_data, missing_data):\n",
    "    \n",
    "    org_df = pd.read_csv(org_data, header=0)\n",
    "    org_df = org_df.drop(['Unnamed: 0'], axis=1)  # Drop columns\n",
    "    # convert the 'Date' column to datetime format\n",
    "    org_df['date'] = pd.to_datetime(org_df['date'])\n",
    "    mis_df = pd.read_csv(missing_data, header=0)\n",
    "#     mis_df = mis_df.drop(['Unnamed: 0'], axis=1)  # Drop columns\n",
    "    mis_df['date'] = pd.to_datetime(mis_df['date'])\n",
    "\n",
    "    frames = [org_df, mis_df]\n",
    "    result = pd.concat(frames)\n",
    "    print('Length of colums: {}'.format(len(result.columns)))\n",
    "\n",
    "    result = result.sort_values(by=['date'])\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Start Script--------\n",
      "--------Start Time: 2020-12-31 21:23:47-------\n",
      "\n",
      "Date of data: 2020_7_19\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_6_29\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_5_16\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_3_30\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_7_20\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_12_7\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_5_6\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_6_10\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_3_27\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_5_12\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_8_4\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_4_22\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_3_23\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_5_2\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_6_14\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_12_3\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_7_24\n",
      "Number of prefectures: 48\n",
      "Date of data: 2020_10_16\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_8_30\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_10_5\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_9_17\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_11_26\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_4_8\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_7_4\n",
      "Number of prefectures: 48\n",
      "Date of data: 2020_12_19\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_8_27\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_12_20\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_8_23\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_11_22\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_9_13\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_10_1\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_10_12\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_12_24\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_8_24\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_7_7\n",
      "Number of prefectures: 48\n",
      "Date of data: 2020_11_25\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_9_14\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_10_6\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_10_15\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_12_23\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_10_11\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_10_2\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_9_10\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_11_21\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_7_3\n",
      "Number of prefectures: 48\n",
      "Date of data: 2020_8_20\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_12_30\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_10_28\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_9_29\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_3_8\n",
      "Number of prefectures: 32\n",
      "Date of data: 2020_9_9\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_11_18\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_8_19\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_12_27\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_5_15\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_8_3\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_6_13\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_6_9\n",
      "Number of prefectures: 48\n",
      "Date of data: 2020_11_8\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_12_4\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_7_23\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_4_21\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_8_7\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_5_11\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_3_19\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_7_27\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_5_1\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_6_17\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_7_30\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_5_28\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_3_13\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_6_24\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_7_14\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_5_22\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_6_7\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_11_6\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_7_10\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_8_9\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_6_20\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_3_17\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_5_31\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_7_29\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_11_2\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_4_16\n",
      "Number of prefectures: 48\n",
      "Date of data: 2020_6_3\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_6_19\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_5_26\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_12_14\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_7_9\n",
      "Number of prefectures: 48\n",
      "Date of data: 2020_10_8\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_8_13\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_11_12\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_9_3\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_9_23\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_10_22\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_4_1\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_12_10\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_10_26\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_9_27\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_9_30\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_11_16\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_9_7\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_10_31\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_8_17\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_12_29\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_10_18\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_9_19\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_4_6\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_11_28\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_12_17\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_8_29\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_10_21\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_9_20\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_11_11\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_8_10\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_12_13\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_4_2\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_8_14\n",
      "Number of prefectures: 48\n",
      "Date of data: 2020_11_15\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_9_4\n",
      "Number of prefectures: 48\n",
      "Date of data: 2020_9_24\n",
      "Number of prefectures: 48\n",
      "Date of data: 2020_10_25\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_7_17\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_4_28\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_6_30\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_6_27\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_5_18\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_12_9\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_11_5\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_6_4\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_5_8\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_5_21\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_6_23\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_7_13\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_5_25\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_11_1\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_4_15\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_9_25\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_10_24\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_8_15\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_11_14\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_9_5\n",
      "Number of prefectures: 48\n",
      "Date of data: 2020_12_12\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_4_3\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_11_10\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_9_1\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_8_11\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_10_20\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_9_21\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_11_29\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_4_7\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_12_16\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_8_28\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_10_19\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_9_18\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_4_14\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_5_24\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_6_1\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_7_12\n",
      "Number of prefectures: 48\n",
      "Date of data: 2020_6_22\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_5_9\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_6_5\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_5_20\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_11_4\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_4_10\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_12_8\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_6_26\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_5_19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of prefectures: 47\n",
      "Date of data: 2020_7_16\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_6_18\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_6_2\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_5_27\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_7_28\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_5_30\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_11_3\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_4_17\n",
      "Number of prefectures: 48\n",
      "Date of data: 2020_8_8\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_6_21\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_3_16\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_7_11\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_11_7\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_4_13\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_5_23\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_6_6\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_7_15\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_3_12\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_6_25\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_11_17\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_9_6\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_8_16\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_12_28\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_10_30\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_10_27\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_9_26\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_3_7\n",
      "Number of prefectures: 29\n",
      "Date of data: 2020_12_11\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_9_22\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_10_23\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_8_12\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_11_13\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_9_2\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_10_9\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_12_15\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_7_8\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_9_8\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_11_19\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_8_18\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_12_26\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_10_29\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_12_31\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_9_28\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_3_9\n",
      "Number of prefectures: 33\n",
      "Date of data: 2020_7_2\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_11_20\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_8_21\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_10_10\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_9_11\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_10_3\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_12_22\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_10_7\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_9_15\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_10_14\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_8_25\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_11_24\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_7_6\n",
      "Number of prefectures: 48\n",
      "Date of data: 2020_6_16\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_5_29\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_7_31\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_7_26\n",
      "Number of prefectures: 48\n",
      "Date of data: 2020_12_1\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_8_6\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_5_10\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_3_18\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_4_20\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_12_5\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_11_9\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_7_22\n",
      "Number of prefectures: 48\n",
      "Date of data: 2020_6_8\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_5_4\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_6_12\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_4_24\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_5_14\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_8_2\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_12_2\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_7_25\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_5_3\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_6_15\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_4_23\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_5_13\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_8_5\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_5_7\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_6_11\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_3_26\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_7_21\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_3_31\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_12_6\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_4_30\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_8_1\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_6_28\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_5_17\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_7_18\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_4_27\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_12_25\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_9_12\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_10_13\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_8_22\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_11_23\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_7_1\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_12_21\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_7_5\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_4_9\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_11_27\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_12_18\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_8_26\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_8_31\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_10_17\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_11_30\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_9_16\n",
      "Number of prefectures: 47\n",
      "Date of data: 2020_10_4\n",
      "Number of prefectures: 47\n",
      "Number of prefectures: 66\n",
      "Index(['date', '滋賀県', '京都府', '大阪府', '兵庫県', '奈良県', '和歌山県', '鳥取県', '島根県', '岡山県',\n",
      "       '広島県', '山口県', '徳島県', '香川県', '愛媛県', '高知県', '福岡県', '佐賀県', '長崎県', '熊本県',\n",
      "       '大分県', '宮崎県', '鹿児島県', '沖縄県', '北海道', '青森県', '岩手県', '宮城県', '秋田県', '山形県',\n",
      "       '福島県', '茨城県', '栃木県', '群馬県', '埼玉県', '千葉県', '東京都', '神奈川県', '新潟県', '富山県',\n",
      "       '石川県', '福井県', '山梨県', '長野県', '岐阜県', '静岡県', '愛知県', '三重県', '⾧崎県', '⾧野県',\n",
      "       '⻑崎県', '⻑崎船その他県', '⻘森県', '⻑野県', '⻑崎船その他その他県', '(その他)県', '岩手県　', '福島県　',\n",
      "       '埼玉県　', '千葉県　', '東京都　', '大阪府　', '広島県　', '香川県　', '合計　県', '愛知県　'],\n",
      "      dtype='object')\n",
      "check this: 66\n",
      "Missing data: [datetime.datetime(2020, 3, 10, 0, 0), datetime.datetime(2020, 3, 11, 0, 0), datetime.datetime(2020, 3, 14, 0, 0), datetime.datetime(2020, 3, 15, 0, 0), datetime.datetime(2020, 3, 20, 0, 0), datetime.datetime(2020, 3, 21, 0, 0), datetime.datetime(2020, 3, 22, 0, 0), datetime.datetime(2020, 3, 24, 0, 0), datetime.datetime(2020, 3, 25, 0, 0), datetime.datetime(2020, 3, 28, 0, 0), datetime.datetime(2020, 3, 29, 0, 0), datetime.datetime(2020, 4, 4, 0, 0), datetime.datetime(2020, 4, 5, 0, 0), datetime.datetime(2020, 4, 11, 0, 0), datetime.datetime(2020, 4, 12, 0, 0), datetime.datetime(2020, 4, 18, 0, 0), datetime.datetime(2020, 4, 19, 0, 0), datetime.datetime(2020, 4, 25, 0, 0), datetime.datetime(2020, 4, 26, 0, 0), datetime.datetime(2020, 4, 29, 0, 0), datetime.datetime(2020, 5, 5, 0, 0)]\n",
      "Total 86399 [sec]\n",
      "-----End Time : 2020-12-31 21:23:48 ---------\n",
      "-----END SCRIPT------\n"
     ]
    }
   ],
   "source": [
    "class Main():\n",
    "    \n",
    "    \"\"\"Transform data\"\"\"\n",
    "    \n",
    "    time = Time()\n",
    "    time.print_start()\n",
    "    \n",
    "    data = Data()\n",
    "    file = File()\n",
    "    \n",
    "    ###Step1: Read in data###\n",
    "    mypath = '../../data/raw/'\n",
    "   \n",
    "#     #国別コロナ数\n",
    "#     txt_paths = file.get_paths(mypath, \".txt\")\n",
    "#     corona_country(mypath, txt_paths)\n",
    "    \n",
    "#     #国内における都道府県別の人口\n",
    "#     path = file.get_paths(mypath, [\"popDensity.csv\", \"area.csv\", \"population.csv\"])\n",
    "#     population_jpn(mypath, path)\n",
    "\n",
    "#     国内における都道府県別のPCR検査陽性者数\n",
    "#     csv_paths = file.get_paths(mypath, [\"corona_jp_1.csv\", \"corona_jp_2.csv\"], starting=\"2020_12_31\")\n",
    "#     pcr_japan(mypath, csv_paths)\n",
    "\n",
    "#     #Get rest of pcr missing data\n",
    "#     mypath = '/Users/rurikoimai/Desktop/corona/data/missing_csv/'\n",
    "#     file_dict = file.get_paths(mypath, [\"corona_jp_1.csv\", \"corona_jp_2.csv\"], starting=\"2020_\")\n",
    "#     pcr_japan(mypath, file_dict)\n",
    "    \n",
    "#     #concat population and pcr df\n",
    "#     file = File()\n",
    "#     pop_data = '../../data/transformed/2020_10_1_population_jp.csv'\n",
    "#     pcr_data = '../../data/transformed/corona_jp/'\n",
    "#     csv_paths = file.get_paths(pcr_data, [\"corona_jp.csv\"], starting=\"2020_12_\")\n",
    "#     recent_file = file.get_recent_file(csv_paths)\n",
    "#     pop_df = pd.read_csv(pop_data, header=0)\n",
    "#     pcr_df = pd.read_csv(pcr_data+recent_file, header=0)\n",
    "#     pop_df = pop_df.set_index('pref')\n",
    "#     pcr_df = pcr_df.set_index('pref')\n",
    "#     frames = [pcr_df, pop_df]\n",
    "#     result = pd.concat(frames, axis=1)\n",
    "#     file.export_table(result, 'pcr_pop_corona_jp', 'csv')\n",
    "    \n",
    "    #Construct time series data###\n",
    "    mypath = '../../data/transformed/corona_jp/'\n",
    "    file_paths = file.get_paths(mypath, \".csv\")\n",
    "    time_series_df(mypath, file_paths)\n",
    "    \n",
    "#     #Format Missing Data\n",
    "#     mypath = '../../data/'\n",
    "#     filename = '2020_1_15_corona_jp_1.csv'\n",
    "#     missing_df = format_missing_data(mypath, filename)\n",
    "#     missing_df = missing_df.set_index('date')\n",
    "#     # add row with next row\n",
    "#     for col in missing_df.columns:\n",
    "#         for i in range(0, len(missing_df)-1):\n",
    "#             missing_df[col].values[i + 1] = missing_df[col].values[i] + missing_df[col].values[i + 1]\n",
    "\n",
    "#     file.export_table(missing_df, 'missing_data_corona_jp', 'csv')\n",
    "    \n",
    "#     #Concat missing data to original data\n",
    "#     org_data = '../../data/transformed/corona_bytime_jp_v0.1.csv'\n",
    "#     missing_data = '../../data/transformed/missing_data_corona_jp.csv'\n",
    "#     result = concat_missing_data(org_data, missing_data)\n",
    "#     file.export_table(result, 'corona_bytime_jp_v0.2', 'csv')\n",
    "\n",
    "#     #Find missing dates \n",
    "#     d = [day for day in result['date'].tolist()]\n",
    "#     date_set = set(d[0] + datetime.timedelta(x) for x in range((d[-1] - d[0]).days))\n",
    "#     missing = sorted(date_set - set(d))\n",
    "#     print(\"Missing data: {}\".format(missing))\n",
    "\n",
    "#     #Update time series data###\n",
    "#     mypath = '../../data/transformed/'\n",
    "#     file_paths = file.get_paths(mypath, \"corona_jp.csv\", starting='2020_12_31')\n",
    "#     time_series_df(mypath, file_paths)\n",
    "#     time_data = '../../data/transformed/corona_bytime_jp_updated.csv'\n",
    "#     recent_data = '../../data/transformed/corona_bytime_jp_today.csv'\n",
    "#     result = concat_missing_data(time_data, recent_data)\n",
    "#     file.export_table(result, 'corona_bytime_jp_updated', 'csv')\n",
    "\n",
    "\n",
    "    \n",
    "    #国内の自殺者数 \n",
    "\n",
    "    time.print_end()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    Main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
